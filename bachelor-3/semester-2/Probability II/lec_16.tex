\lecture{16}{Mon 10 Feb 2020 08:31}{Gamma Distribution Intro}
A refresher from last class:
\begin{align*}
        p_{X}( x_{1} , … , x_{r} ) = \begin{cases}
                \binom{n }{x_1 \ldots x_{r}} p_r ^{x_1} p_{2} ^{x_2}… p_r ^{x_r}, & ( x_{1} ,\ldots , x_{r} ) \in  S_{x} \\
                0, & otherwise
        \end{cases}
\end{align*}

An alternative way to write the joint pmf of a Multinomial distribution with parameters $n, p_{1} , \ldots , p_{r}$ is as a joint pmf on $\left( r - 1 \right) $-dimensional space, as follows (This is completely analogous to what we did with the Multivariate Hypergeometric joint pmf). Let $X = \left( X_{1} , \ldots , X_{r-1} \right) $.

Then:
\begin{align*}
	P\left( X_1 = x_1, \ldots , X_{r-1} = x_{r - 1} \right) &=  P\left( X_1 = x_1, \ldots , X_{r-1} = x_{r - 1}, X_{r} = n - x_1 - \ldots - x_{r-1} \right) \\
	= \binom{n}{x_1 x_2 \ldots x_{r-1}\left( n - x_1 - \ldots - x_{r-1} \right) }&p^{x_{1}}_{1} , \ldots , p^{x_{r-1}}_{r-1} \times \left( 1 - p_1 - \ldots - p_{r-1} \right) ^{n - x_1 - \ldots - x_{r - 1}}
.\end{align*}

for $\left( x_{1} , \ldots , x_{r-} \right) \in  S_{X}$, where
\[
	S_{X} = \left\{ \left( x_{1} , \ldots , x_{r-1} \right) \in \real^{r - 1}  \mid x_{i}\in \left\{ 0, \ldots, n \right\} , \ x_{1} + \ldots + x_{r-1} \le  n \right\} 
.\] 
If $r = 2$, we get the usual form of the Binomial $\left( n, p \right) $ pmf:
\begin{align*}
	P\left( X_1 = x_1 \right) &= \binom{n}{x_1,  n - x_1 }  p^{x_1}\left( 1 - p \right) ^{n - x_1}\\
				  &= \binom{n }{x_1}p^{x_1}\left( 1 - p \right) ^{n - x_1}
.\end{align*}
where $p = p_1$, $x_1 = 0, 1, \ldots, n$.

\section{Marginal Distributions}

Let $\left\{ i_{1} , \ldots , i_{k} \right\} \subset \left\{ 1, \ldots, n \right\} $. Relabel the outcomes in each multinomial experiment that are not of type $i_{1} , \ldots , i_{k}$ as "O" (an O, not a zero), for "Other". Then each multinomial experiment will have $k + 1$ possible types of outcomes, types $i_{1} , \ldots , i_{k}$ and O, with probabilites $p_{i_{1}} , \ldots , p_{i_{}}$, $p_{O} = 1 - p_{i_{1}} - \ldots - p_{i_{k}}$. Then:
\begin{align*}
	P\left( X_{i_{1}} = x_{i _{1}}, \ldots, X_{i_{k}} = x_{i_{k}} \right) &= 
	P\left( X_{i_{1}} = x_{i _{1}}, \ldots, X_{i_{k}} = x_{i_{k}}, X_{O} = n - x_{i_{1}} - \ldots - x_{i_{k}} \right)\\ 
									      &= \binom{n}{x_{i_1} \ldots x_{i_{k}} n - x_{i_1} - \ldots - x_{i_k}  }p^{x_{i_k}}_{i_1} , \ldots , p^{x_{i_1}}_{i_k} \times \left( 1 - p_{i_1} - \ldots - p_{i_k} \right) ^{n - x_{i_1} - \ldots - x_{i_k}}
.\end{align*}
for $x_{i_{j}} \in  \left\{ 0, 1, \ldots, n \right\} $, $j = 1, \ldots, k$ and $x_{i_1} + \ldots + x_{i_{k}} \le  n$.

This gives the joint pmf of $\left( X_{i_{1}} , \ldots , X_{i_{n}} \right) ^{T}$.

\begin{eg}
	(HW 4 \# 1(b)) Roll a fair die 10 times , what is the probability that a 1 or 2 appears three times, and a 3 appears four times. 

	Consider each roll as a multinomial trial where the outcomes are 1, 2, 3, 4, 5 or 6, with probabilities  $\frac{1}{6}$ for each outcome. Relabel the outcomes as 
	\begin{align*}
		a &= 1 \text{ or } 2, p_{a} = \frac{1}{3} \\
		b &= 3, p_{b} = \frac{1}{6} \\
		c &= 4, 5,  \text{ or } 6 , p_{c} = \frac{1}{2}
	.\end{align*}
	Then we want 
	\begin{align*}
		P\left( X_{a} = 3, X_{b} = 4 \right) &= \binom{10}{3 \ 4 \ 3} \left( \frac{1}{3} \right) ^{3} \left( \frac{1}{6} \right) ^{4} \left( \frac{1}{2} \right) ^3  \\
		&= 0.015
	.\end{align*}
\end{eg}


\section{The Gamma Distribution}

A random variable $X$ is said to have a Gamma distribution with parameters $r > 0$ and $\lambda > 0$ if it has pdf 
 \[
	 f_{X}\left( x \right) = \begin{cases}
		 \frac{\lambda ^{r}}{\Gamma \left( r \right) } x^{r - 1}e ^{- \lambda x}, & x > 0 \\
		 0, & \text{otherwise}
	 \end{cases}
 .\] 
 where 
 \[
 \Gamma \left( r \right)  = \int_{0}^{\infty} y ^{r - 1} e ^{-y} dy,\quad \text{for } r > 0
 .\] 
