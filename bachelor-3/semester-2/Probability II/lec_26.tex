\lecture{26}{Thu 12 Mar 2020 13:44}{Covariance Matrix}
Note that 
 \[
	 \rho\left( X,X \right) = \frac{Cov\left( X, X \right) }{\sqrt{Var\left( X \right) Var\left( X \right) } } = \frac{Var\left( X \right) }{Var\left( X \right) } = 1
\] 
which is evident from the fact that $X$ is linear function of $X$. 

\section{Covariance Matrices and Cross Covariance Matrices}

Let $X = \left( X_{1} , \ldots , X_{n} \right) ^{T}$ and $Y = \left( Y_{1} , \ldots , Y_{m} \right) ^{T}$ be two random vectors. 

Define their cross covariance matrix, $Cov\left( X, Y \right) $ as the $n \times  m$ matrix with $\left( i, j \right) ^{\text{th}}$ entry $Cov\left( X_i , Y_j \right) $, $i = 1 , \ldots , n$, $j = 1, \ldots , m$. ie 
\[
	Cov\left( X, Y \right)  = E\left[ XY^{T} \right]  - E\left[ X \right] E\left[ Y^{T} \right] 
.\] 
where expectation is taken componentwise.

We have a special case when $X = Y$. In this case, $Cov\left( X, X \right) $ is called the covariance matrix of $X$. More commonly this is denoted as $Cov\left( X \right) $. 

Similarity we'll let $\rho\left( X, Y \right) $ and $\rho\left( X \right) $ denote the $n \times m$ and $n \times n$ correlation matrices, given by 
\begin{align*}
	\rho\left( X, Y \right) _{i, j} &= \rho\left( X_i , Y_j  \right)  \\
	\rho\left( X \right) _{i, j} &=  P\left( X_i , X_j \right) 
.\end{align*}
Note that the main diagonal of $\rho \left( X \right) $ is all ones.
% `````````````````````````
Recall that if $X_{1} , \ldots , X_{n}$ and $Y_{1} , \ldots , Y_{m}$ are random variables, and $a_{1} , \ldots , a_{n}$ and $b_{1} , \ldots , b_{m}$ are real constants, then 
\begin{align*}
	Cov\left( \sum_{i=1}^{n} a_i X_i , \sum_{j=1}^{m} b_j Y_j \right) = \sum_{i=1}^{n } \sum_{j=1}^{m} a_i b_j Cov\left( X_i , Y_j  \right) 
.\end{align*}
If we let $a = \left( a_{1} , \ldots , a_{n} \right) ^{T}$ and $b = \left( b_{1} , \ldots , b_{m} \right) ^{T}$, then in matrix vector format the above is 
\[
	Cov\left( a^{T}X, b^{T}Y \right) = a^{T}Cov\left( X, Y \right) b
.\]
If your write it out this is standard vector notation.

This generalizes. Let 
\[
A = \begin{bmatrix} \quad A_1 \quad  \\ \vdots \\ A_n \end{bmatrix} 
\] 

where $A$ is $\left( r \times  n \right) $, and $A_i$ is the i-th row $\left( 1\times n \right) $. Let 
\[
B = \begin{bmatrix} \quad B_1 \quad  \\ \vdots \\ B_n \end{bmatrix} 
\] 

where $B$ is $\left( s \times  n \right) $, and $B_j$ is the j-th row $\left( 1\times n \right) $. Then $A \cdot Cov\left( X, Y \right) \cdot B^{T}$ is the $r \times  s$ matrix whose $\left( i, j \right) ^{\text{th}}$ entry is 
\[
	\left( \text{i-th row of }A \right) \cdot Cov\left( X, Y \right) \cdot\left( \text{j-th column of }B \right) 
.\] 
Therefore, 
\begin{align*}
	A_i Cov\left( X, Y \right) B_j ^{T} &= Cov\left( A_i X, B _j Y  \right) \\
					    &= Cov\left( \left( AX \right) _i , \left( BY \right) _j \right)  \\
					    &= \left( i , j  \right) ^{\text{th}} \text{ entry of }Cov\left( AX,\ BY \right) 
.\end{align*} 
$Cov\left( AX, \ BY \right) $ is here an $r \times s$ matrix. Therefore, 
\[
	Cov\left( AX, \ BY \right)  = A \cdot Cov\left( X, Y \right) \cdot B^{T}
.\]
There is a special case when $X = Y$ get 
\[
	Cov\left( AX, \ BY \right)  = A\cdot Cov\left( X \right) \cdot B^{T}
.\] 
If we have $A = B$ then in this case 
\[
	Cov\left( AX \right)  = A \cdot Cov\left( X \right) \cdot A^{T}
.\] 
If $A$ is $1 \times  n$, ie, $A = a^{T}$ then 
\begin{align*}
	Cov\left( a^{T}X, a^{T}X \right)  &=  a^{T}Cov\left( X \right) a \\
					  &= Var\left( a ^{T}X \right)  \\
.\end{align*}

\subsection{Properties of Covariance Matrixes}

\begin{enumerate}
	\item $Cov\left( X \right) $ is nonegative definite for any random vector $X$, ie, $a^{T}Cov\left( X \right) a \ge  0$for every $a \in \real^{n}$. 
		\begin{proof}
			Let $a \in  \real^{n}$, then 
			\[
				a ^{T}Cov\left( X \right) a
			.\] 
		\end{proof}
	\item 
	\item If $X$ is a continuous random vector, then if $Cov\left( X \right) $ is singular then $X$ has no joint pdf. 
		\begin{proof}
			If $Cov\left( X \right) $ is singular then there is a vector $a \in  R^{n}$ such that $Cov\left( X \right) a = 0$. 

			Then $Var\left( a^{T}X \right) = a^{T}Cov\left( X \right) a = 0 $. Therefore 
			\[
				P\left( a^{T}X = C \right)  = 1
			\] 
			for some constant $C$. Ie, $X$ lies on the (zero-volume in  $\real^{n}$) hyperplane defined by $\left\{ x \in  \real^{n} | a ^{T}x = C \right\}  = S$. So there can be no density satisfying 
			\[
				\int_{S} f\left( x_{1} , \ldots , x_{n} \right)  dx_{1} , \ldots , dx_{n}  = 1
			.\] 
		\end{proof}
\end{enumerate}
